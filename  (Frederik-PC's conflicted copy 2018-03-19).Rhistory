OR(data,"Short","Medium","14-24","50-60")
OR(data,"Short","Medium", "14-24", "25-34")
(data,"Short","Medium", "25-34", "35-49")
OR(data,"Short","Medium", "25-34", "35-49")
OR(data,"Short","Medium","35-49", "50-60")
OR(data,"Short","Medium", "14-24", "25-34")*OR(data,"Short","Medium", "25-34", "35-49")
OR(data,"Short","Medium", "14-24", "25-34")
OR(data,"Short","Medium", "14-24", "25-34")*OR(data,"Short","Medium", "25-34", "35-49")
(57*345)/(230*226)
OR(data,"Short","Medium","35-49", "50-60")
OR(data,"Short","Medium", "14-24", "25-34")*OR(data,"Short","Medium", "25-34", "35-49")*OR(data,"Short","Medium","35-49", "50-60")
OR(data,"Short","Medium", "14-24", "25-34")
OR(data,"Short","Medium", "25-34", "35-49")
OR(data,"Short","Medium","35-49", "50-60")
OR(data,"Short","Medium", "25-34", "35-49")
139/226
207/345
OR(data,"Short","Medium","35-49", "50-60")
LAT <- array(c(664,2,84,80),
dim=c(2,2),
dimnames= list(HItest = c("Positive","Negative"),
LATtest = c("Positive", "Negative"))
)
LAT
margin(LAT,1)
margin.table(LAT,1)
LAT<-cbind(LAT,margin.table(LAT,1))
LAT
LAT
LAT <- array(c(664,2,84,80),
dim=c(2,2),
dimnames= list(HItest = c("Positive","Negative"),
LATtest = c("Positive", "Negative"))
)
margin.lat <- margin.table(LAT,1)
LAT<-cbind(LAT,margin.lat)
(LAT)
p.fp <- LAT["Negative","Positive"]/LAT["Negative","margin.lat"]
p.fn <- LAT["Positive","Negative"]/LAT["Positive","margin.lat"]
p.fp
p.fn
p.fn
quit
quit()
quit()
crabs <- read.table("crabs.txt", header = TRUE,
colClasses = c("factor", "factor", "numeric",
"numeric", "numeric", "numeric")
)
m <- glm(y ~ color, data = crabs, family = binomial)
summary(m)
library(dplyr)
colorcrabs <- summarise(group_by(crabs, color),
present = sum(y),
absent = sum(1-y),
total = n())
m <- glm(cbind(present, absent) ~ color, data = colorcrabs, family = binomial)
summary(m)
## parameters are directly the log odds
m.noint <- glm(cbind(present, absent) ~ color-1, data = colorcrabs, family = binomial)
summary(m.noint)
## Sample logits equal the estimated log odds
colorcrabs <- mutate(colorcrabs,
log(present)-log(absent))
m.empty <- glm(cbind(present, absent) ~ 1, data = colorcrabs, family = binomial)
summary(m.empty)
## testing using -2(L_H0 - L_S)
## Note that the larger model is saturated and therefore has deviance 0
pchisq(deviance(m.empty) - deviance(m.noint), df = 3, lower.tail = FALSE)
## Same: deviance(m) - deviance(m.empty)
anova(m.empty, m, test = "Chisq")
drop1(m, test = "Chisq")
## This is not the same... Dropping color leaves us with the model of no intercept
## (uniform distribution on presence/absence)
drop1(m.noint, test = "Chisq")
m.zero <- glm(cbind(present, absent) ~ -1, data = colorcrabs, family = binomial)
summary(m.zero)
## Numerical color
colorcrabs <- mutate(colorcrabs,
num.color = as.numeric(color))
m.linear <- glm(cbind(present, absent) ~ num.color, data = colorcrabs, family = binomial)
summary(m.linear)
## Deviance goodness of fit
pchisq(deviance(m.linear), df = df.residual(m.linear), lower.tail = FALSE)
crabs$color <- relevel(crabs$color, ref = "5")
m1 <- glm(y ~ color + weight, data = crabs, family = binomial)
m2 <- glm(y ~ color*weight, data = crabs, family = binomial)
pchisq(deviance(m1)-deviance(m2), df.residual(m1)-df.residual(m2), lower.tail = FALSE)
AIC(m1)
AIC(m2)
summary(m1)
## Deviance gof OK -- but not applicable due to binary data.
pchisq(deviance(m1), df.residual(m1), lower.tail = FALSE)
## Pearson gof OK  -- but not applicable due to binary data.
pchisq(sum(residuals(m1, "pearson")^2), df.residual(m1), lower.tail = FALSE)
plot(rstandard(m1, type = "pearson") ~ crabs$weight)
crabs <- read.table("crabs.txt", header = TRUE,
colClasses = c("factor", "factor", "numeric",
"numeric", "numeric", "numeric")
)
m <- glm(y ~ color, data = crabs, family = binomial)
summary(m)
library(dplyr)
colorcrabs <- summarise(group_by(crabs, color),
present = sum(y),
absent = sum(1-y),
total = n())
m <- glm(cbind(present, absent) ~ color, data = colorcrabs, family = binomial)
summary(m)
## parameters are directly the log odds
m.noint <- glm(cbind(present, absent) ~ color-1, data = colorcrabs, family = binomial)
summary(m.noint)
## Sample logits equal the estimated log odds
colorcrabs <- mutate(colorcrabs,
log(present)-log(absent))
m.empty <- glm(cbind(present, absent) ~ 1, data = colorcrabs, family = binomial)
summary(m.empty)
## testing using -2(L_H0 - L_S)
## Note that the larger model is saturated and therefore has deviance 0
pchisq(deviance(m.empty) - deviance(m.noint), df = 3, lower.tail = FALSE)
## Same: deviance(m) - deviance(m.empty)
anova(m.empty, m, test = "Chisq")
drop1(m, test = "Chisq")
## This is not the same... Dropping color leaves us with the model of no intercept
## (uniform distribution on presence/absence)
drop1(m.noint, test = "Chisq")
m.zero <- glm(cbind(present, absent) ~ -1, data = colorcrabs, family = binomial)
summary(m.zero)
## Numerical color
colorcrabs <- mutate(colorcrabs,
num.color = as.numeric(color))
m.linear <- glm(cbind(present, absent) ~ num.color, data = colorcrabs, family = binomial)
summary(m.linear)
## Deviance goodness of fit
pchisq(deviance(m.linear), df = df.residual(m.linear), lower.tail = FALSE)
crabs$color <- relevel(crabs$color, ref = "5")
m1 <- glm(y ~ color + weight, data = crabs, family = binomial)
m2 <- glm(y ~ color*weight, data = crabs, family = binomial)
pchisq(deviance(m1)-deviance(m2), df.residual(m1)-df.residual(m2), lower.tail = FALSE)
AIC(m1)
AIC(m2)
summary(m1)
## Deviance gof OK -- but not applicable due to binary data.
pchisq(deviance(m1), df.residual(m1), lower.tail = FALSE)
## Pearson gof OK  -- but not applicable due to binary data.
pchisq(sum(residuals(m1, "pearson")^2), df.residual(m1), lower.tail = FALSE)
plot(rstandard(m1, type = "pearson") ~ crabs$weight)
library(dplyr)
source('C:/Users/Frederik/Desktop/dismod/Uger/Week 5_ Exercises/Crabs.R', echo=TRUE)
crabs <- read.table("crabs.txt", header = TRUE,
colClasses = c("factor", "factor", "numeric",
"numeric", "numeric", "numeric")
)
x<-5*5
xmin = 0
xmin = 0
xmax = 20
Nsteps = 20
dx = (xmax-xmin)/(Nsteps-1)
xgrid <- 1:Nsteps*dx
xgrid
dx = (xmax-xmin)/(Nsteps)
xgrid <- 1:Nsteps*dx
(xgrid <- 1:Nsteps*dx)
(xgrid <- 0:(Nsteps-1)*dx)
dx = (xmax-xmin)/(Nsteps-1)
(xgrid <- 0:(Nsteps-1)*dx)
mat = 1
Ntime = 20
dt = mat/(Ntime-1)
(tgrid <- 0:(Ntime-1)*dt)
drif = (rate-dividend)*xgrid
rate = 0.4
dividend = 0
vol = 2
alpha = 0.5
theta = 0.5
strike = 10
drif = (rate-dividend)*xgrid
(drif = (rate-dividend)*xgrid)
rate = 0.1
dividend = 0
vol = 2
alpha = 0.5
theta = 0.5
strike = 10
(drif = (rate-dividend)*xgrid)
(xgrid <- 0:(Nsteps-1)*dx)
Nsteps = 19
dx = (xmax-xmin)/(Nsteps-1)
(xgrid <- 0:(Nsteps-1)*dx)
xmin = 0
xmax = 20
Nsteps = 21
(xgrid <- 0:(Nsteps-1)*dx)
dx = (xmax-xmin)/(Nsteps-1)
mat = 1
Ntime = 21
dt = mat/(Ntime-1)
(tgrid <- 0:(Ntime-1)*dt)
rate = 0.1
dividend = 0
vol = 2
alpha = 0.5
theta = 0.5
strike = 10
(drif = (rate-dividend)*xgrid)
Nsteps = 21
dx = (xmax-xmin)/(Nsteps-1)
(xgrid <- 0:(Nsteps-1)*dx)
mat = 1
Ntime = 21
dt = mat/(Ntime-1)
(tgrid <- 0:(Ntime-1)*dt)
rate = 0.1
dividend = 0
vol = 2
alpha = 0.5
theta = 0.5
strike = 10
(drif = (rate-dividend)*xgrid)
(sigma = vol*vol*xgrid^2)
(sigma = vol*vol*xgrid^(2*alpha))
(sigma = vol*vol*xgrid^(2*alpha))
agrid<-(1-theta)/(2*dx)*(drift  - sigma2/dx)
(drift = (rate-dividend)*xgrid)
(sigma2 = vol*vol*xgrid^(2*alpha))
agrid<-(1-theta)/(2*dx)*(drift  - sigma2/dx)
agrid
b<-1/dt + (1-theta)*(rate+sigma2/dx^2)
b
source('C:/Users/Frederik/Desktop/kz.R', echo=TRUE)
(agrid<-(1-theta)/(2*dx)*(drift  - sigma2/dx))
(d<- -theta/(2*dx)*(drift - sigma2/dx))
(agrid<-(1-theta)/(2*dx)*(drift  - sigma2/dx))
(bgrid<-1/dt + (1-theta)*(rate+sigma2/dx^2))
(cgrid<-(1-theta)/(2*dx)*(-drift - sigma2/dx))
(e<- 1/dt - theta*(rate + sigma2/(dx^2)))
(f <- theta/(2*dx)*(drift + sigma2/dx))
(f <- theta/(2*dx)*(drift + sigma2/dx))
xmin = 0
xmax = 20
Nsteps = 21
dx = (xmax-xmin)/(Nsteps-1)
(xgrid <- (Nsteps-1)*dx):0
mat = 1
Ntime = 21
dt = mat/(Ntime-1)
(tgrid <- (Ntime-1)*dt):0
(tgrid <- (Ntime-1)*dt):0
dt = mat/(Ntime-1)
mat = 1
Ntime = 21
dt = mat/(Ntime-1)
(tgrid <- (Ntime-1)*dt):0
xmin = 0
xmax = 20
Nsteps = 21
dx = (xmax-xmin)/(Nsteps-1)
(xgrid <- ((Nsteps-1)*dx):0)
mat = 1
Ntime = 21
dt = mat/(Ntime-1)
(tgrid <- ((Ntime-1)*dt):0)
rate = 0.1
dividend = 0
xmin = 0
xmax = 20
Nsteps = 21
dx = (xmax-xmin)/(Nsteps-1)
(xgrid <- (Nsteps-1):0*dx)
mat = 1
Ntime = 21
dt = mat/(Ntime-1)
(tgrid <- (Ntime-1):0*dt)
rate = 0.1
dividend = 0
vol = 2
alpha = 0.5
theta = 0.5
strike = 10
(drift = (rate-dividend)*xgrid)
(sigma2 = vol*vol*xgrid^(2*alpha))
(agrid<-(1-theta)/(2*dx)*(drift  - sigma2/dx))
(bgrid<-1/dt + (1-theta)*(rate+sigma2/dx^2))
(cgrid<-(1-theta)/(2*dx)*(-drift - sigma2/dx))
(d<- -theta/(2*dx)*(drift - sigma2/dx))
(e<- 1/dt - theta*(rate + sigma2/(dx^2)))
(f <- theta/(2*dx)*(drift + sigma2/dx))
w<-matrix(0, nrow = Nsteps, ncols=timesteps)
matrix(0, nrow = Nsteps, ncols=timesteps)
w<-matrix(0, nrow = Nsteps, ncols=Ntime)
w<-matrix(0, nrow = Nsteps, ncol=Ntime)
w<-matrix(0, nrow = Nsteps, ncol=Ntime)
w
(strike-xgrid[strike-xgrid>0])
xgrid[strike-xgrid>0]
xgrid
w[,1] <- max(exp(-rate*mat)*(strike-xgrid),0)
w[,1]
max(exp(-rate*mat)*(strike-xgrid[]),0)
w[,1] <- fmax(exp(-rate*mat)*(strike-xgrid[]),0)
w[,1] <- pmax(exp(-rate*mat)*(strike-xgrid),0)
w[,1]
# covariance matrix
cov = matrix(rep(0.4,50*50), nrow=50, ncol= 50)
# covariance matrix
cov = diag(matrix(rep(0.4,50*50), nrow=50, ncol= 50))=1
# covariance matrix
cov = matrix(rep(0.4,50*50), nrow=50, ncol= 50)
diag(cov)=1
# Choleski decomp
A = chol(cov)
# Simulation of iid normals
N = rnorm(50)
S = rchisq(50, 3)
Y = A%*%Z
# Simulation of iid normals
Z = rnorm(50)
# Simulation of chi with df=3
S = rchisq(1, 3)
Y = A%*%Z
# Simulation of chi with df=3
nu = 3
S = rchisq(1, nu)
Y = A%*%Z
X = sqrt(nu)
X = sqrt(nu)/sqrt(S)*Y
# QRM HOMEWORK 2 #
n = 50
nu = 3
# covariance matrix
cov = matrix(rep(0.4,50*50), nrow=50, ncol= 50)
diag(cov)=1
# Choleski decomp
A = chol(cov)
# Simulation of iid normals
Z = rnorm(n)
# Simulation of chi with df=3
S = rchisq(1, nu)
# Simulation of the t's
Y = A%*%Z
X = sqrt(nu)/sqrt(S)*Y
X = 1/(100*sqrt(3))*sqrt(nu)/sqrt(S)*Y
dnorm(1:5)
# Copula
U = dnorm(X)
X
dnorm(X)
# Copula
U= pnorm(X)
U
(exp(U)-1)
# Loss
L = -sum(100*(exp(U)-1)
)
# Loss
L = -sum(100*(exp(U)-1))
sum(exp(U)-1)
plot(X)
i=1
((i-1)*n):(i*n)
i=5
((i-1)*n):(i*n)
i=sample
((i-1)*n):(i*n)
sample
sample=10000
sample(1:5)
i=sample
((i-1)*n):(i*n)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
((i-1)*n):(i*n)
i=1
((i-1)*n):(i*n)
((i-1)*(n-1)+1):(i*n)
i=4
((i-1)*(n-1)+1):(i*n)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
plot(L)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
plot(Z[1])
plot(Z[1,])
plot(Z[2,])
A
A%*%t(A)
t(A)%*%A
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
t(A)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
plot(X)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
sort(5:2)
sort(1,2,435,34,53, decreasing=T)
sort(1,2,435,34,53, decreasing=T)
sort(5:1, decreasing=T)
sort(5:1:6, decreasing=T)
sort(1:6, decreasing=T)
sort(-6:6, decreasing=T)
vaR.G = sort(LG, decreasing = T)[length(LG)*0.99+1]
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
vaR.G = LG.sort[length(LG.sort)*0.99+1]
# Something must be wrong
#plot(LG)
LG.sort = sort(LG, decreasing = T)
vaR.G = LG.sort[length(LG.sort)*0.99+1]
ES.G = mean(LG.sort[(length(LG.sort)*0.99+1):length(LG.sort)])
length(LG)*(1-0.99)+1
sample*(1-0.99)+1
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
phi
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
source('C:/Users/Frederik/Desktop/QRM2.R', echo=TRUE)
plot(LC)
setwd(Sys.getenv("masters-thesis"))
source("Kernels/kernels.R")
source("Estimation/estimates.R")
tester<-function(testfun, norm = 1, sub = T, mode = FALSE, h = hd, t.index = 10000,
mean = 0, sd = sig, noise = 0, rho=0, last = 1,
t = 0:10000, mat = 1, N = 1000, plt = FALSE){
# runs the testfun(ction) N times and returns mean/var/values/(plot)
# sd is multiplied by sqrt(dt)
simAR<-function(n, rho, sd){
X<-rep(NA,n)
X[1]<-rnorm(1, 0, sd/(1-rho))
eps<-rnorm(n-1,0,sd)
for(i in 2:n){
X[i] <- rho*X[i-1]+eps[i-1]
}
return(X)
}
dt <- mat/t[length(t)]
out <- numeric(N)
eps.last <- numeric(N)
for(i in 1:N)
{
x <- rnorm(length(t) , mean = mean*dt, sd = sd*sqrt(dt))
x <- cumsum(x)
if(rho != 0){
eps <- simAR(length(t), rho, noise)
}
else{
eps <- rnorm(length(t), mean = 0, sd = noise)
}
y <- x + eps
data<-data.frame(time = t*dt, Y = y)
out[i]<-as.numeric(testfun(data, h, t.index = t.index, originalEstimator = mode)[2])
out[i] <- norm*(out[i]-mean*sub)
eps.last[i] <- eps[length(t)]
if(i == 1){
plot(y, type="l")
}
}
if(plt){
qqnorm(out)
abline(0,sd(out))
}
return(list(mean = mean(out), var = var(out), val = out, noise = noise, eps = eps.last))
}
# deets
hd <- 0.01 #bandwidth
test4 <- tester(est.mu, hd, F, T, mean = 1, sd = 1, noise = 0.01, rho = 0.1, plt = F, last = 0.1)
test4$eps
test4$val
plot(test4$eps - test4$val)
plot((test4$eps - test4$val)/test4$eps, ylim = c(-100,100))
plot(test4$eps - test4$val)
plot((test4$eps - test4$val)/test4$eps, ylim = c(-100,100))
plot(test4$eps - test4$val)
plot((test4$eps - test4$val)/test4$eps, ylim = c(-100,100))
# AR NOISE w DRIFT #
test4 <- tester(est.mu, hd, F, T, mean = 1, sd = 1, noise = 0.01, rho = 0.1, plt = F, last = 0.1)
test5 <- tester(est.mu, hd, F, T, mean = 1, sd = 1, noise = 0.01, rho = 0, plt = F, last = 0.1)
test5$eps
test5$val
plot(test5$eps - test5$val)
plot((test5$eps - test5$val)/test5$eps, ylim = c(-100,100))
max( (test5$eps - test5$val) /test5$eps )
test6 <- tester(est.mu, hd, F, T, mean = 1, sd = 1, noise = 0.05, rho = 0, plt = F, last = 0.1)
test6$eps
test6$val
plot(test6$eps - test6$val)
plot((test6$eps - test6$val)/test6$eps, ylim = c(-100,100))
max( (test6$eps - test6$val) /test6$eps )
test5 <- tester(est.mu, hd, F, T, mean = 1, sd = 1, noise = 0.01, rho = 0, plt = F, last = 0.1)
test5$eps
test5$val
plot(test5$eps - test5$val)
plot((test5$eps - test5$val)/test5$eps, ylim = c(-100,100))
max( (test5$eps - test5$val) /test5$eps )
test6 <- tester(est.mu, hd, F, T, mean = 1, sd = 1, noise = 0.05, rho = 0, plt = F, last = 0.1)
test6$eps
test6$val
plot(test6$eps - test6$val)
plot((test6$eps - test6$val)/test6$eps, ylim = c(-100,100))
test7 <- tester(est.mu, hd, F, T, mean = 1, sd = 0.5, noise = 0.01, rho = 0, plt = F, last = 0.1)
test7$eps
test7$val
plot(test7$eps - test7$val)
plot((test7$eps - test7$val)/test7$eps, ylim = c(-100,100))
